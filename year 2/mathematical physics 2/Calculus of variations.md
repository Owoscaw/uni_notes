
The [[Differentiable Functions#Differentiable results|extrema]] of a function, $\rho(s):\Re\to\Re$, at the point $s=s_0$ can be found when:$$\Huge \left.\frac{d\rho(s)}{ds}\right|_{s=s_0}=0$$An alternative but equivalent formulation of this:$$\Huge \rho(s+\delta s)=\rho(\delta s)+(\delta s)\frac{d\rho(s)}{ds}+R(s,\delta s)$$This comes from the [[Taylor series|Taylor expansion]] of the function $\rho(s)$, where $\delta s$ is a small change in $s$, and $R(s,\delta s)$ is some error term. It is convienient to define:$$\Huge \delta\rho(s):=\rho(s+\delta s)-\rho(s)$$We then get:$$\Huge \delta\rho(s)=(\delta s)\frac{d\rho(s)}{ds}+R(s,\delta s)$$Note that by the definition of the derivative we get:$$\Huge \lim_{\delta s\to 0}R(s,\delta s)=\lim_{\delta s\to 0}\left[\rho(\delta s+s)-\rho(s)-(\delta s)\frac{d\rho(s)}{ds}\right]$$Now by the limit definition of $\frac{d\rho(s)}{ds}$, we have:$$\Huge \lim_{\delta s\to 0}\frac{R(s,\delta s)}{\delta s}=\lim_{\delta s\to0}\left[\frac{\delta\rho(s)}{\delta s}-\frac{d\rho(s)}{ds}\right]=0$$Which follows since the two terms on the right become equivalent in the infantesimal limit. Assuming $R(s,\delta s)$ has a regular Taylor expansion on $\delta s$, we get that:$$\Huge R(s,\delta s)=r_2(\delta s)^2+r_3(\delta s)^3+\dots$$We see that $R(s,\delta s)$ is of at least quadratic order, we denote this by saying:$$\Huge R(s,\delta s)=\mathcal{O}((\delta s)^2)$$Therefore we deduce that $\rho(s)$ has an extremum when:$$\Huge \delta\rho(s)=\mathcal{O}((\delta s)^2)$$
Generalising to a function, $\rho:\Re^n\mapsto\Re$, of $n$ variables, we have:$$\Huge \rho(s_1+\delta s_1,\dots,s_n+\delta s_n)=\rho(s_1,\dots,s_n)+\sum_{i=1}^n\delta s_i\frac{\partial\rho(s_i)}{\partial s_i}+\mathcal{O}((\delta s)^2)$$Stationary points of $\rho$ are therefore located where $\frac{\partial\rho(s_i)}{\partial s_i}$ for all $i$, that is to say $\delta\rho=\mathcal{O}((\delta s)^2)$. These occur wherever $\delta\rho$ vanishes to first order in $\delta s_i$ for all $i$.

# Functionals:

A functional is a map from functions to numbers, for example:$$\Huge S[y(t)]=\int_{t_0}^{t_1}(y(t))^2dt$$A function, $y(t)$, can be stationary with respect to a functional, $S[y(t)]$ if:$$\Huge \left.\frac{dS[y(t)+\epsilon z(t)]}{d\epsilon}\right|_{\epsilon=0}=0$$For all smooth $z(t)$ such that $z(t_0)=z(t_1)=0$, where $\epsilon\in\Re$. This restriction ensures that the $z(t)$ term does not affect $y(t)$ at the endpoints $(t_0,t_1)$.

Consider the Taylor expansion of $S[y(t)+\epsilon z(t)]$ in $\epsilon$:$$\Huge S[y(t)+\epsilon z(t)]=S[y(t)]+\epsilon\frac{dS[y(t)+\epsilon z(t)]}{d\epsilon}+\frac{1}{2}\epsilon^2\frac{d^2[y(t)+\epsilon z(t)]}{d\epsilon^2}+\dots$$Since the derivative of $S$ wrt $\epsilon$ vanishes at zero, all higher order term vanish. So we get:$$\large \delta S:=S[y(t)+\epsilon z(t)]-S[y(t)]=S[y(t)+\delta y(t)]-S[y(t)]=\frac{1}{2}\epsilon^2\frac{d^2S[y(t)+\delta y(t)]}{d\epsilon^2}
$$Therefore, since this starts at the second order in $\epsilon$, we write:$$\Huge \delta S:=\mathcal{O}((\delta y)^2)$$
# Action principle:

There is some functional $S[y(t)]$ such that physical paths, $y(t)$, are stationary with respect to $S$

Consider a function $f(x)$ continuous in $[a,b]$ and such that $\int_a^bf(x)g(x)dx=0$ for all smooth $g(x)$ such that $g(a)=g(b)=0$. Then $f(x)=0$ for all $x\in(a,b)$. We assume that there exists some $p\in(a,b)$ such that $f(p)>0$. Then by continuity of $f$ there exists $p_0<p<p_1$ such that $f(x)>0\,\forall x\in(p_0,p_1)$. Choose:$$\Huge g(x)=\begin{cases}\nu(x-p_0)\nu(p_1-x)&x\in[p_0,p_1]\\0&\text{otherwise}\end{cases},\,\,\nu(s):=\exp{\left(-\frac{1}{s}\right)}$$With such choice of $g$, we consider our assumption:
$$\Huge 0=\int_a^bf(x)g(x)dx=\int_{p_0}^{p_1}f(x)g(x)dx$$Inside this integral, we have that $f(x)>\delta>0$ in the integral (by assumption). We also have that $g(x)>0$ for all $x\in(p_0,p_1)$. Therefore we have that the above integral is greater than zero, since both functions are positive between the bounds of the integral. A similar proof exists for the case where $f(x)<0$. We therefore get a contradiction. Therefore, since our assumptions hold, we have that $f(x)=0\,\forall x\in(a,b)$


# Euler-Lagrange equations:

We assume that $S[y(t)]$ takes form:$$\Huge S[y(t)]=\int_{t_0}^{t_1}L(y(t),\dot y(t))dt$$We also assume that $L$ is a function that maps $\Re^2$ to $\Re$.

For a particle moving in one dimension, $x(t)$, we have that:$$\Huge \frac{d}{dt}\left(\frac{\partial L(x,\dot x)}{\partial \dot x(t)}\right)-\frac{\partial L(x,\dot x)}{\partial x(t)}=0$$To prove this, we use the above assumption about the form of $S[y(t)]$:$$\large S[x(t)]=\int_{t_0}^{t_1}L(x,\dot x)dt\implies S[x(t)+\delta x(t)]=\int_{t_0}^{t_1}L(x(t)+\delta x(t),\dot x(t)+\delta \dot x(t))dt$$Consider the Taylor expansion of $L(x+\delta x,\dot x+\delta\dot x)$ up to the first order:$$\Huge L(x+\delta x,\dot x+\delta \dot x)=L(x,\dot x)+\frac{\partial L(x,\dot x)}{\partial x}\delta x+\frac{\partial L(x,\dot x)}{\partial \dot x}\delta \dot x+\dots$$Now putting this into variation of action ($S$):$$ \delta S=S[x+\delta x,\dot x+\delta\dot x]=\int_{t_0}^{t_1}L(x+\delta x,\dot x+\delta\dot x)-L(x,\dot x)=\int_{t_0}^{t_1}\frac{\partial L(x,\dot x)}{\partial x}\delta x+\frac{\delta L(x,\dot x)}{\partial\dot x}\delta \dot x+\dots dt$$Here, the $L(x,\dot x)$ term from the expansion and the $-L(x,\dot x)$ term from the integral cancel out, and terms of quadratic order and higher have been omitted. So we have:$$\Huge \delta S=\int_{t_0}^{t_1}\frac{\partial L}{\partial x}\delta x+\frac{\partial L}{\partial \dot x}\delta\dot x\dots dt$$Note that $x(t)$ and $\dot x(t)$ are simply numbers, the more accurate way to write the above partial derivatives is:$$\Huge \left.\frac{\partial L(r,s)}{\partial r}\right|_{(r,s)=(x(t),\dot x(t))}$$We continue the proof by noting that $\delta\dot x(t)=\frac{d}{dt}(\delta x(t))$:$$\Huge \delta S=\int_{t_0}^{t_1}\frac{\partial L}{\partial x}\delta x+\frac{\partial L}{\partial \dot x}\frac{d}{dt}(\delta x)dt$$Integration by parts can now be used on the second term to give the following:$$\Huge \delta S=\int_{t_0}^{t_1}\left(\frac{\partial L}{\partial x}-\frac{d}{dt}\left(\frac{\partial L}{\partial \dot x}\right)\right)\delta x+ \frac{d}{dt}\left(\delta x\frac{\partial L}{\partial \dot x}\right)dt$$Since the last term is now a total derivative, we write:
$$\Huge \delta S=\int_{t_0}^{t_1}\left(\frac{\partial L}{\partial x}-\frac{d}{dt}\left(\frac{\partial L}{\partial \dot x}\right)\right)\delta x\,dt+\left[\delta x\frac{\partial L}{\partial \dot x}\right]_{t_0}^{t_1}$$Note that $x(t_0)=x(t_1)=0$, so the right hand term vanishes. We then have:$$\Huge \delta S=\int_{t_0}^{t_1}\left(\frac{\partial L}{\partial x}-\frac{d}{dt}\left(\frac{\partial L}{\partial \dot x}\right)\right)\delta x\,dt$$As we have proved above, the action principle demands that this integral vanishes and equals zero. So we get the result as required.

Note that $L(r,s)$ is simply a function of $2n$ variables and does not care about paths, however since we evaluate this at $r=x(t),s=\dot x(t)$, we are interested in the study of this function with small changes to $r,s$. This is why we use the chain rule in its Taylor expansion.

# Configuration space and generalised coordinates:

The set of all possible instantaneous configurations for a given physical system is known as the configuration space, denoted by $C$. This includes positions but not velocities. This space is required before the Lagrangian can be constructed:
> A particle moving in $\Re^d$ has configuration space of $\Re^d$
> $N$ particles moving in $\Re^d$ has configuration space $\Re^{dN}$, assuming that all $N$ particles are distinguishable
> Two particles joined by a rod of length $l$ in $d$ dimensions reduces the possible positions of the second particle, written as:$$\Huge ||\underline x_1-\underline x_2||^2=l^2$$The configuration space of this physical system is therefore $2d-1$ dimensional.
> Consider a rigid body in $\Re^3$. The position of the centre of mass defines three dimensions, and three rotational angles defines a further three, making the configuration space for this system six dimensional.

Given a configuration space $C$ for a physical system $S$, we say that $S$ has $\dim{C}$ degrees of freedom. Any set of coordinates in $C$ are known as generalised coordinates, we use $q_i$ for $i\in\{1,\dots,\dim{C}\}$ to denote said coordinates and $\underline q$ to denote the vector with said coordinates. We are dealing with unconstrained generalised coordinates when describing a configuration space, that is a set of exactly $\dim{C}$ coordinates and no more, these should locally describe the geometry of the configuration space.

The derivation of the Euler-Lagrange equations can now be repeated for a general configuration space $C$. Consider a general path in configuration space given by $q(t)\in C$, and assume the existence of a Lagrangian function, $L(q,\dot q)$, such that the action for the path is given by:$$\Huge S=\int_{t_0}^{t_1}L(q(t),\dot q(t))dt$$The variation principle then states that for fixed initial and final positions in the configuration space ($q(t_0)=q^{(0)},q(t_1)=q^{(1)}$), then the path taken by the physical system satisfies:$$\Huge \delta S=0$$Up to first order in $\delta q(t)$. The derivation is now similar to the previous, here $N=\dim C$:$$\large \delta S=\int_{t_0}^{t_1}\sum_{i=1}^N\frac{\partial L}{\partial q_i}\delta q_i+\sum_{i=1}^N\frac{\partial L}{\partial\dot q_i}\delta\dot q_i\,dt=\int_{t_0}^{t_1}\sum_{i=1}^N\frac{\partial L}{\partial q_i}\delta q_i+\sum_{i=1}^N\frac{\partial L}{\partial\dot q_i}\frac{d}{dt}(\delta q_i)\,dt$$This is simply using the fact that $\frac{d}{dt}(\delta q_i)=\delta\dot q_i$. Now we combine the summations:$$\Huge \delta S=\int_{t_0}^{t_1}\sum_{i=1}^N\left(\frac{\partial L}{\partial q_i}-\frac{d}{dt}\left(\frac{\partial L}{\partial \dot q_i}\right)\right)\delta q_i+\frac{d}{dt}\left(\delta q_i\frac{\partial L}{\partial \dot q_i}\right)\,dt$$Now the right hand term is a total derivative, so can be integrated easily:$$\Huge \delta S=\left[\sum_{i=1}^N\delta q_i\frac{\partial L}{\partial\dot q_i}\right]_{t_0}^{t_1}+\int_{t_0}^{t_1}\sum_{i=1}^N\left(\frac{\partial L}{\partial q_i}-\frac{d}{dt}\left(\frac{\partial L}{\partial \dot q_i}\right)\right)\delta q_i\,dt$$Since we are using unconstrained coordinates, each $q_i$ can vary independently in configuration space. Since we have $N$ independenet coordinates, the fundamental lemma can be applied leading to a system of $N$ partial differential equations:$$\Huge \frac{\partial L}{\partial q_i}-\frac{d}{dt}\left(\frac{\partial L}{\partial \dot q_i}\right)=0\,\,\forall i\in\{1,\dots,N\}$$We call these the Euler-Lagrange equations. These satisfy any configuration space, since no assumtions about the coordinate system were made. Similar to the case where we had one dimension, $x$, we get the following:$$\Huge \frac{\partial q_i}{\partial \dot q_j}=\frac{\partial \dot q_i}{\partial q_j}=0,\,\,\frac{\partial q_i}{\partial q_j}=\frac{\partial \dot q_i}{\partial\dot q_j}=\delta _{ij}$$Where $\delta$ is the [[Matrix definition#Special matrices|Kronecker delta]] function.

Note that when dealing with a Lagrangian that takes time as an input, for example $L(q,\dot q,t)$, one should treat all three inputs as independent, as the Lagrangian is now a function of $2\dim C+1$ variables (generalized coordinates, their velocities, and time). The inputs are only related when building the action from the Lagrangian, for example take $L=\frac{1}{2}m\dot x^2-\frac{1}{2}t^2x^2$ we have:$$\Huge \frac{\partial L}{\partial \dot x}=m\dot x,\,\,\frac{\partial L}{\partial x}=xt^2,\,\,\frac{\partial L}{\partial t}=-tx^2$$